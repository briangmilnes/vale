/*
  Do some testing on building and proving unrolled loops.

*/

include "../../arch/x64/decls.vad"
include "../../arch/x64/decls64.vad"
include{:verbatim} "../../arch/x64/print.s.dfy"
include{:verbatim} "../../lib/util/dafny_wrappers.i.dfy"
include{:verbatim} "loopunroll.s.dfy" 
include{:verbatim} "seqcomp.s.dfy" 
include{:verbatim} "addrlogic.s.dfy" 

#verbatim
module LoopUnroll {

import opened x64_def_s
import opened x64_vale_i
import opened x64_print_s
import opened dafny_wrappers_i
import opened x64_decls_i
import opened x64_decls64_i
import opened LoopUnrollModule
import opened seqcomp
import opened addrlogic

#endverbatim


/*
// The simple case to prove, registers in no addition.
procedure {:refined} {:bridge} IncrementUint64(ghost id: heaplet_id) 
    reads    rdi; rsi; r8;
    modifies mem; efl; r9;
    requires/ensures ValidSrcAlAddr64(mem, id, addroff64(r8,0), Public);
    ensures r8 == old(r8);
    ensures OnlyUpdatesAddr64(old(mem), mem, id, addroff64(old(r8),0), Public,
                 BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8),0))].v, 8));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddr64(mem, id, addroff64(r8,0), Public);
  Load64(r9, r8, 0, Public, id);
  Add64Wrap(r9,1); // Hard 8. 
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Add64Wrap(r9,1);
  Store64(r8, r9, 0, Public, id);
}
*/

procedure {:refined} {:bridge} AddN(inout operand r : uint64, inline n : uint8)
    modifies efl;
    requires r + n < 0x1_0000_0000_0000_0000;
    ensures  r == BitwiseAdd64(old(r), n);
{
   lemma_BitwiseAdd64();
   Add64Wrap(r, n);
} 

// This case works only without refined and without operator names, all must be operands.
// requires {:refined false} @readtmpreg != @addtmpreg && @ioreg != @readtmpreg && @ioreg != @addtmpreg;
// also fails to prove. 
procedure {:bridge} {:timeLimitMultiplier 3} ReadIncrStore(inout operand ioreg : uint64,
                                             inout operand addtmpreg  : uint64,
                                             ghost id : heaplet_id,
                                             inline off : uint64)

    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;

    requires @ioreg != @addtmpreg;
    requires/ensures ValidSrcAlAddr64(mem, id, addroff64(ioreg, off), Public);
    ensures ioreg == old(ioreg);
    ensures OnlyUpdatesAddr64(old(mem), mem, id, addroff64(old(ioreg), off), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(ioreg),off))].v, 8));
    ensures ValidDstAlAddr64(mem, id, addroff64(ioreg,off));
{
    lemma_BitwiseAdd64();
    lemma_ValidSrcAlAddr64(mem, id, addroff64(ioreg,off), Public);
    Load64(addtmpreg, ioreg, off * 8, Public, id);
    incr64(addtmpreg);// Hard 8, http://www.imdb.com/title/tt0119256/. 
    incr64(addtmpreg);
    incr64(addtmpreg);
    incr64(addtmpreg);
    incr64(addtmpreg);
    incr64(addtmpreg);
    incr64(addtmpreg);
    incr64(addtmpreg);
    Store64(ioreg, addtmpreg, off * 8, Public, id);
}     

// Get rid of the recursion to try and unroll.
/*
procedure IncrementUint64UnrolledByHand1 (ghost id: heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;

    requires r8 < 0x1_0000_0000_0000_0000 - 8;
    requires ValidSrcAlAddr64(mem, id, addroff64(r8, 0), Public);

    ensures OnlyUpdatesAddr64(old(mem), mem, id, addroff64(old(r8), 0), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8), 0))].v, 8));
    ensures OnlyAdd64Modified(old(mem), mem, id, addroff64(old(r8), 0));
{
  lemma_ValidSrcAlAddr64(mem, id, addroff64(r8,0), Public);
  ReadIncrStore(r8, r9, id, 0);
  AddN(r8, 8);
}
*/

/*
procedure IncrementUint64UnrolledByHand2(ghost id: heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;

    requires r8 < 0x1_0000_0000_0000_0000 - 16;
    requires ValidSrcAlAddr64(mem, id, addroff64(r8, 0), Public);
    requires ValidSrcAlAddr64(mem, id, addroff64(r8, 1), Public);

    ensures UpdatesAddr64(old(mem), mem, id, addroff64(old(r8), 0), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8), 0))].v, 8));
    ensures UpdatesAddr64(old(mem), mem, id, addroff64(old(r8), 1), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8), 1))].v, 8));
    ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), 2));
{
  lemma_ValidSrcAlAddr64(mem, id, addroff64(r8, 0), Public);
  lemma_ValidSrcAlAddr64(mem, id, addroff64(r8, 1), Public);
  ReadIncrStore(r8, r9,  id, 0);
  ReadIncrStore(r8, r10, id, 1);
  AddN(r8, 16);
}
*/

/*
procedure IncrementUint64UnrolledByHand2s(ghost id : heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;
    requires r8 < 0x1_0000_0000_0000_0000 - 16;
    requires ValidSrcAlAddrs64(mem, id, addrs64(old(r8), 2), Public);

    ensures  UpdatesAddr64(old(mem), mem, id, addroff64(old(r8),0), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8),0))].v, 8));
    ensures  UpdatesAddr64(old(mem), mem, id, addroff64(old(r8),1), Public,
               BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8),1))].v, 8));
    ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), 2));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(r8,2), Public);
  ReadIncrStore(r8, r9,  id, 0);
  ReadIncrStore(r8, r10, id, 1);
  AddN(r8, 16);
}
*/

// This works nicely but needs to have the seq replaced with a function of n.

/*
procedure IncrementUint64UnrolledByHand2DualSeqOutput(ghost id : heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;

    requires r8 < 0x1_0000_0000_0000_0000 - 16;
    requires ValidSrcAlAddrs64(mem, id, addrs64(old(r8), 2), Public);

    ensures  UpdatesAlAddrs64(old(mem), mem, id, addrs64(old(r8),2), Public,
               seq2(BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8),0))].v, 8),
                    BitwiseAdd64(old(mem)[id].mem64[EvalAddrOff64(addroff64(old(r8),1))].v, 8)));
    ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), 2));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(r8,2), Public);
  ReadIncrStore(r8, r9,  id, 0);
  ReadIncrStore(r8, r10, id, 1);
  AddN(r8, 16);
}
*/

#verbatim
function Plus8(old_mem : Heaplets, id: heaplet_id, ar : Addrs64, count : nat) : seq<uint64>
 requires 0 < count <= ar.count;
 requires ValidDstAlAddrs64(old_mem, id, ar);
 ensures |Plus8(old_mem, id, ar, count)| == count;
 decreases count;
{
  lemma_ValidDstAlAddrs64(old_mem, id, ar);
  if count == 1 then
     [BitwiseAdd64(old_mem[id].mem64[EvalAddrOff64(addroff64(ar.addr, count - 1))].v, 8)]
  else 
    //assert EvalAddrOff64(addroff64(ar.addr, count - 1)) in old_mem[id].mem64;
    Plus8(old_mem, id, ar, count - 1) + 
    [BitwiseAdd64(old_mem[id].mem64[EvalAddrOff64(addroff64(ar.addr, count - 1))].v, 8)]
}
#endverbatim


/*
procedure IncrementUint64UnrolledByHand2Fun(ghost id : heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;

    requires r8 < 0x1_0000_0000_0000_0000 - 16;
    requires ValidSrcAlAddrs64(mem, id, addrs64(old(r8), 2), Public);

    ensures  UpdatesAlAddrs64(old(mem), mem, id, addrs64(old(r8),2), Public,
                  Plus8(old(mem), id, addrs64(old(r8),2), 2));
    ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), 2));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(r8,2), Public);
  ReadIncrStore(r8, r9,  id, 0);
  ReadIncrStore(r8, r10, id, 1);
  AddN(r8, 16);
}
*/

/*
procedure IncrementUint64UnrolledByHand4Fun(ghost id : heaplet_id)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15;
  
    requires r8 < 0x1_0000_0000_0000_0000 - 32;
    requires ValidSrcAlAddrs64(mem, id, addrs64(old(r8), 4), Public);

    ensures  UpdatesAlAddrs64(old(mem), mem, id, addrs64(old(r8), 4), Public,
                  Plus8(old(mem), id, addrs64(old(r8),4), 4));
    ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), 4));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(r8,2), Public);
  ReadIncrStore(r8,  r9, id, 0);
  ReadIncrStore(r8, r10, id, 1);
  ReadIncrStore(r8, r11, id, 2);
  ReadIncrStore(r8, r12, id, 3);
  AddN(r8, 32);
}
*/

/*
// Hmm, can't get the addressing.
procedure {:recursive} {:timeLimitMultiplier 2}  IncrementUint64Unrolled(ghost id : heaplet_id, inline step : nat, inline offset : nat)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx;
    requires r8 < 0x1_0000_0000_0000_0000 - (offset + step) * 8;
    requires 1 <= step <= 8;
    requires/ensures ValidSrcAlAddrs64(mem, id, addrs64(old(r8), step), Public);
//    ensures r8 == old(r8) + (offset + steps) * 8;

//   ensures  UpdatesAlAddrs64(old(mem), mem, id,  addrs64(old(r8), step), Public,
//                Plus8(old(mem), id, addrs64(old(r8), step), step));

//   ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), step));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(old(r8), step), Public);
  inline if (step == 8) {
    ReadIncrStore(r8, r9,  id, 7);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 7) {
    ReadIncrStore(r8, r10,  id, 6);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 6) {
    ReadIncrStore(r8, r11,  id, 5);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 5) {
    ReadIncrStore(r8, r12,  id, 4);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 4) {
    ReadIncrStore(r8, r13,  id, 3);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 3) {
    ReadIncrStore(r8, r14,  id, 2);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 2) {
    ReadIncrStore(r8, r15,  id, 1);
    IncrementUint64Unrolled(id, step - 1, offset + 1);
  } else if (step == 1) {                                    
    ReadIncrStore(r8, rbx, id, 0);
    AddN(r8, (offset * 8) % 0x1_00);
 }   
}
*/

procedure {:recursive} {:timeLimitMultiplier 2}  IncrementUint64Unrolled(ghost id : heaplet_id, inline step : nat, inline steps : nat)
    modifies mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx;
    requires r8 < 0x1_0000_0000_0000_0000 - steps * 8;
    requires step <= steps;
    requires 1 <= steps <= 8;
    requires 0 <= step <= 8;
    requires/ensures ValidSrcAlAddrs64(mem, id, addrs64(old(r8), steps), Public);

// Won't prove.
   ensures  UpdatesAlAddrs64(old(mem), mem, id,  addrs64(old(r8), step), Public,
                 Plus8(old(mem), id, addrs64(old(r8), step), step));

//   ensures OnlyAddrs64Modified(old(mem), mem, id, addrs64(old(r8), step));
{
  lemma_BitwiseAdd64();
  lemma_ValidSrcAlAddrs64(mem, id, addrs64(old(r8),steps), Public);
  inline if (step == 8) {
    ReadIncrStore(r8, r9,  id, 7);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 7) {
    ReadIncrStore(r8, r10,  id, 6);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 6) {
    ReadIncrStore(r8, r11,  id, 5);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 5) {
    ReadIncrStore(r8, r12,  id, 4);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 4) {
    ReadIncrStore(r8, r13,  id, 3);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 3) {
    ReadIncrStore(r8, r14,  id, 2);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 2) {
    ReadIncrStore(r8, r15,  id, 1);
    IncrementUint64Unrolled(id, step - 1, steps);
  } else if (step == 1) {                                    
    ReadIncrStore(r8, rbx, id, 0); // I hope rbx is unused.
    IncrementUint64Unrolled(id, step - 1, steps);    
  } else if (step == 0) {
    AddN(r8, (steps * 8) % 0x1_00);
 }   
}

/*
procedure {:refined} {:bridge} SaveRegisters()
    modifies stack; mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx; rsi;
    requires/ensures HasStackSlots(stack, 20);
{

//  Sub32(rsp,16);  I don't see how to adjust the stack pointer.
  StoreStack64(0, r8);
  StoreStack64(2, r9);
  StoreStack64(4, r10);
  StoreStack64(6, r11);
  StoreStack64(8, r12);
  StoreStack64(10, r13);
  StoreStack64(12, r14);
  StoreStack64(14, r15);
  StoreStack64(16, rbx);
  StoreStack64(18, rsi);
}         


procedure {:refined} {:bridge} RestoreRegisters()
    modifies stack; mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx; rsi;
    requires HasStackSlots(stack, 20);
{
  LoadStack64(r8, 0);
  LoadStack64(r9, 2);
  LoadStack64(r10, 4);
  LoadStack64(r11, 6);
  LoadStack64(r12, 8);
  LoadStack64(r13, 10);
  LoadStack64(r14, 12);
  LoadStack64(r15, 14);
  LoadStack64(rbx, 16);
  LoadStack64(rsi, 18);
  // Add32(rsp,16); I don't see how to adjust the stack pointer.
} 


procedure IncrementVectorUnrolled1(ghost id : heaplet_id) 
    reads    rdi; rsi;
    modifies stack; mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx; rsi; rdi;
    requires HasStackSlots(stack,16);
    requires r8 < 0x1_0000_0000_0000_0000 - rsi * 8;
    requires ValidSrcAlAddrs64(mem, id, addrs64(rdi, rsi), Public);
{
  SaveRegisters();
  Mov64(r8, rdi);
  Add64(rsi, rdi);
  while (r8 < rsi)
   invariant true;   
   decreases r8 - rsi;
   {
     assume r8 < 0x1_0000_0000_0000_0000 - 1 * 8;
     IncrementUint64Unrolled(id, 1, 1);
   }
  assume HasStackSlots(stack,16);
  RestoreRegisters();
}
*/

/*
procedure IncrementVectorUnrolled4(ghost id : heaplet_id) 
    reads    rdi; rsi;
    modifies stack; mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx; rsi; rdi;
    requires HasStackSlots(stack,16);
    requires r8 < 0x1_0000_0000_0000_0000 - rsi * 8;
    requires ValidSrcAlAddrs64(mem, id, addrs64(rdi, rsi), Public);
{
  SaveRegisters();
  Mov64(r8, rdi);
  Add64(rsi, rdi);
  while (r8 < rsi)
   invariant true;   
   decreases r8 - rsi;
   {
     assume r8 < 0x1_0000_0000_0000_0000 - 4 * 8;
     IncrementUint64Unrolled(id, 4, 4);
   }
  assume HasStackSlots(stack,16);
  RestoreRegisters();
}

procedure IncrementVectorUnrolled8(ghost id : heaplet_id) 
    reads    rdi; rsi;
    modifies stack; mem; efl; rdx; rcx; r8; r9; r10; r11; r12; r13; r14; r15; rbx; rsi; rdi;
    requires HasStackSlots(stack,16);
    requires r8 < 0x1_0000_0000_0000_0000 - rsi * 8;
    requires ValidSrcAlAddrs64(mem, id, addrs64(rdi, rsi), Public);
{
  SaveRegisters();
  Mov64(r8, rdi);
  Add64(rsi, rdi);
  while (r8 < rsi)
   invariant true;   
   decreases r8 - rsi;
   {
     assume r8 < 0x1_0000_0000_0000_0000 - 8* 8;
     IncrementUint64Unrolled(id, 8, 8);
   }
  assume HasStackSlots(stack,16);
  RestoreRegisters();
}
*/

#verbatim
} 
#endverbatim
